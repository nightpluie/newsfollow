#!/usr/bin/env python3
"""æª¢æŸ¥ ETtoday æ˜¯å¦çˆ¬åˆ°ç‰¹å®šæ–°è"""

import sys
sys.path.insert(0, '.')

from main import RequestsCrawler, extract_signals, normalize_title
from bs4 import BeautifulSoup

# ç›®æ¨™é—œéµå­—
target_keywords = ["è³´æ¸…å¾·", "ä½•æ¬£ç´”", "å°ä¸­"]

print("=" * 60)
print("ğŸ” æª¢æŸ¥ ETtoday çˆ¬å–çµæœ")
print("=" * 60)

crawler = RequestsCrawler()

urls = [
    "https://www.ettoday.net/news/news-list.htm",
    "https://www.ettoday.net/news/focus/ç„¦é»æ–°è/",
    "https://www.ettoday.net/news/hot-news.htm",
]

all_found = []

for url in urls:
    print(f"\nğŸ“° çˆ¬å–: {url}")
    try:
        html = crawler.fetch_html(url)
        soup = BeautifulSoup(html, 'html.parser')

        selectors = [
            "h3 a",
            ".part_list_2 h3 a",
            ".piece h3 a",
        ]

        found_count = 0
        for selector in selectors:
            for link in soup.select(selector):
                title = link.get_text(strip=True)

                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç›®æ¨™é—œéµå­—
                if all(keyword in title for keyword in target_keywords):
                    found_count += 1
                    print(f"   âœ… æ‰¾åˆ°: {title}")
                    all_found.append(title)

        if found_count == 0:
            print(f"   âŒ æœªæ‰¾åˆ°åŒ…å«æ‰€æœ‰é—œéµå­—çš„æ–°è")

    except Exception as e:
        print(f"   âš ï¸  éŒ¯èª¤: {e}")

print("\n" + "=" * 60)
print("ğŸ“Š ç¸½çµ:")
print(f"æ‰¾åˆ° {len(all_found)} å‰‡ç›¸é—œæ–°è")
if all_found:
    for i, title in enumerate(all_found, 1):
        print(f"{i}. {title}")
else:
    print("âŒ æ²’æœ‰æ‰¾åˆ°åŒ…å«ã€è³´æ¸…å¾· + ä½•æ¬£ç´” + å°ä¸­ã€‘çš„æ–°è")
print("=" * 60)
