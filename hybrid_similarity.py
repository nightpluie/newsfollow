#!/usr/bin/env python3
"""
æ··åˆç›¸ä¼¼åº¦æ¯”å°ç­–ç•¥ - æ¼”ç®—æ³• + LLM å…©éšæ®µåˆ¤æ–·
ä½¿ç”¨æœ€ä¾¿å®œçš„ LLMï¼ˆGPT-4o-miniï¼‰è™•ç†é‚Šç·£æ¡ˆä¾‹
"""

from __future__ import annotations

import os
from typing import List, Dict, Optional

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
try:
    from dotenv import load_dotenv
    load_dotenv()  # å¾ .env æª”æ¡ˆè¼‰å…¥ç’°å¢ƒè®Šæ•¸
except ImportError:
    print("âš ï¸  æœªå®‰è£ python-dotenvï¼Œè«‹åŸ·è¡Œ: pip install python-dotenv")

from openai import OpenAI
from main import title_similarity, TitleFeatures


class HybridSimilarityChecker:
    """
    æ··åˆç›¸ä¼¼åº¦æª¢æŸ¥å™¨

    ç­–ç•¥ï¼š
    1. éšæ®µ 1ï¼šæ¼”ç®—æ³•å¿«é€Ÿéæ¿¾
       - ç›¸ä¼¼åº¦ > 0.6 â†’ ç›´æ¥åˆ¤å®šç‚ºç›¸åŒ âœ…
       - ç›¸ä¼¼åº¦ < 0.3 â†’ ç›´æ¥åˆ¤å®šç‚ºä¸åŒ âŒ
       - 0.3 â‰¤ ç›¸ä¼¼åº¦ â‰¤ 0.6 â†’ é€²å…¥éšæ®µ 2

    2. éšæ®µ 2ï¼šLLM ç²¾ç¢ºåˆ¤æ–·
       - ä½¿ç”¨ GPT-4o-miniï¼ˆæœ€ä¾¿å®œï¼‰
       - ç°¡å–® promptï¼šåˆ¤æ–·æ˜¯å¦ç‚ºåŒä¸€äº‹ä»¶
    """

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4.1-nano-2025-04-14", enable_llm: bool = True, timeout: int = 10):
        """
        åˆå§‹åŒ–æ··åˆæª¢æŸ¥å™¨

        Args:
            api_key: OpenAI API Keyï¼ˆå¦‚æœªæä¾›å‰‡å¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
            model: OpenAI æ¨¡å‹åç¨±ï¼ˆé è¨­ gpt-4.1-nano-2025-04-14ï¼Œæ›´å¿«æ›´ä¾¿å®œï¼‰
            enable_llm: æ˜¯å¦å•Ÿç”¨ LLMï¼ˆFalse å‰‡åªç”¨æ¼”ç®—æ³•ï¼‰
            timeout: API è«‹æ±‚è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œé è¨­ 10 ç§’
        """
        self.enable_llm = enable_llm
        self.client = None
        self.model = model
        self.timeout = timeout
        self.llm_call_count = 0  # çµ±è¨ˆ LLM èª¿ç”¨æ¬¡æ•¸

        if enable_llm:
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            if not api_key:
                print("âš ï¸  æœªè¨­å®š OPENAI_API_KEYï¼ŒLLM æ¯”å°åŠŸèƒ½å°‡è¢«åœç”¨")
                self.enable_llm = False
            else:
                # è¨­å®š timeout é¿å…è«‹æ±‚å¡ä½
                import httpx
                self.client = OpenAI(
                    api_key=api_key,
                    timeout=httpx.Timeout(self.timeout, connect=5.0)  # ç¸½è¶…æ™‚ + é€£æ¥è¶…æ™‚
                )
                print(f"âœ… æ··åˆç›¸ä¼¼åº¦æª¢æŸ¥å™¨å·²å•Ÿç”¨ LLM åŠŸèƒ½ï¼ˆ{model}ï¼Œtimeout={timeout}sï¼‰")

    def is_same_news(self, title1: Union[str, TitleFeatures], title2: Union[str, TitleFeatures]) -> bool:
        """
        åˆ¥æ–·å…©å‰‡æ–°èæ˜¯å¦ç‚ºåŒä¸€äº‹ä»¶
        æ”¯æ´å­—ä¸²æˆ– TitleFeatures
        """
        # éšæ®µ 1ï¼šæ¼”ç®—æ³•å¿«é€Ÿéæ¿¾
        # title_similarity å·²ç¶“æ”¯æ´ TitleFeaturesï¼Œç›´æ¥å‚³éå³å¯
        algo_similarity = title_similarity(title1, title2)

        # é«˜ç›¸ä¼¼åº¦ï¼šç›´æ¥åˆ¤å®šç‚ºç›¸åŒ
        if algo_similarity >= 0.6:
            return True

        # ä½ç›¸ä¼¼åº¦ï¼šç›´æ¥åˆ¤å®šç‚ºä¸åŒ
        if algo_similarity < 0.3:
            return False

        # ä¸­é–“åœ°å¸¶ï¼ˆ0.3-0.6ï¼‰ï¼šä½¿ç”¨ LLM ç¢ºèª
        if self.enable_llm and self.client:
            # LLM éœ€è¦åŸå§‹æ–‡å­—
            t1_text = title1.text if isinstance(title1, TitleFeatures) else title1
            t2_text = title2.text if isinstance(title2, TitleFeatures) else title2
            return self._llm_check_similarity(t1_text, t2_text)
        else:
            # å¦‚æœ LLM æœªå•Ÿç”¨ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥ï¼ˆ0.5 é–¾å€¼ï¼‰
            return algo_similarity >= 0.5

    def _llm_check_similarity(self, title1: str, title2: str) -> bool:
        """
        ä½¿ç”¨ LLM åˆ¤æ–·å…©å‰‡æ–°èæ˜¯å¦ç‚ºåŒä¸€äº‹ä»¶
        """
        try:
            self.llm_call_count += 1

            prompt = f"""åˆ¤æ–·ä»¥ä¸‹å…©å‰‡å°ç£æ–°èæ¨™é¡Œæ˜¯å¦å ±å°åŒä¸€äº‹ä»¶ã€‚

æ¨™é¡Œ 1: {title1}
æ¨™é¡Œ 2: {title2}

åˆ¤æ–·æ¨™æº–ï¼š
- å¦‚æœå…©å‰‡æ–°èçš„æ ¸å¿ƒäº‹ä»¶ã€äººç‰©ã€åœ°é»ç›¸åŒï¼Œå³ä½¿å ±å°è§’åº¦ä¸åŒï¼Œä¹Ÿç®—åŒä¸€äº‹ä»¶
- ä¾‹å¦‚ï¼šã€Œå¯‡ä¸–å‹³é“æ­‰äº†ã€å’Œã€Œå¯‡ä¸–å‹³å–Šè©±åŠ‡çµ„åœæ­¢è£½ä½œã€éƒ½æ˜¯é—œæ–¼åŒä¸€å€‹é“æ­‰äº‹ä»¶

åªå›ç­” yes æˆ– noï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""

            response = self.client.chat.completions.create(
                model=self.model,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹
                messages=[{"role": "user", "content": prompt}],
                max_tokens=5,
                temperature=0
            )

            answer = response.choices[0].message.content.strip().lower()
            result = answer == "yes"
            return result

        except Exception as e:
            # å€åˆ†è¶…æ™‚éŒ¯èª¤å’Œå…¶ä»–éŒ¯èª¤
            import httpx
            if isinstance(e, (httpx.TimeoutException, httpx.ConnectTimeout, httpx.ReadTimeout)):
                print(f"â±ï¸  LLM èª¿ç”¨è¶…æ™‚ï¼Œå›é€€åˆ°æ¼”ç®—æ³•åˆ¤æ–·")
            else:
                print(f"âŒ LLM èª¿ç”¨å¤±æ•—: {type(e).__name__}: {e}")
            # å¤±æ•—æ™‚å›é€€åˆ°æ¼”ç®—æ³•ï¼ˆ0.5 é–¾å€¼ï¼‰
            return title_similarity(title1, title2) >= 0.5

    def batch_check(self, candidate_title: Union[str, TitleFeatures], reference_titles: List[Union[str, TitleFeatures]]) -> bool:
        """
        æ‰¹æ¬¡æª¢æŸ¥ï¼šåˆ¤æ–·å€™é¸æ¨™é¡Œæ˜¯å¦èˆ‡åƒè€ƒæ¨™é¡Œåˆ—è¡¨ä¸­çš„ä»»ä½•ä¸€å‰‡ç›¸åŒ
        æ”¯æ´å‚³å…¥é è¨ˆç®—çš„ TitleFeatures ä»¥æå‡æ•ˆèƒ½
        """
        for ref_title in reference_titles:
            if self.is_same_news(candidate_title, ref_title):
                return True
        return False

    def get_statistics(self) -> Dict:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        return {
            'llm_enabled': self.enable_llm,
            'llm_call_count': self.llm_call_count,
        }

    def reset_statistics(self):
        """é‡ç½®çµ±è¨ˆè³‡è¨Š"""
        self.llm_call_count = 0


# ========== æ¸¬è©¦ç¨‹å¼ç¢¼ ==========

def test_hybrid_checker():
    """æ¸¬è©¦æ··åˆæª¢æŸ¥å™¨"""

    print("\n" + "=" * 60)
    print("ğŸ§ª æ¸¬è©¦æ··åˆç›¸ä¼¼åº¦æª¢æŸ¥å™¨")
    print("=" * 60)

    # å»ºç«‹æª¢æŸ¥å™¨ï¼ˆéœ€è¦è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼‰
    checker = HybridSimilarityChecker(enable_llm=True)

    # æ¸¬è©¦æ¡ˆä¾‹ 1: å®Œå…¨ç›¸åŒ
    print("\næ¸¬è©¦ 1: å®Œå…¨ç›¸åŒ")
    t1 = "å°ç©é›»è‚¡åƒ¹å‰µæ–°é«˜"
    t2 = "å°ç©é›»è‚¡åƒ¹å‰µæ–°é«˜"
    result = checker.is_same_news(t1, t2)
    print(f"  {t1} vs {t2}")
    print(f"  çµæœ: {result} (é æœŸ: True)")

    # æ¸¬è©¦æ¡ˆä¾‹ 2: åŒä¸€äº‹ä»¶ä¸åŒåˆ‡è§’ï¼ˆæœƒè§¸ç™¼ LLMï¼‰
    print("\næ¸¬è©¦ 2: åŒä¸€äº‹ä»¶ä¸åŒåˆ‡è§’ï¼ˆè§¸ç™¼ LLMï¼‰")
    test_pairs = [
        ("å¿«è¨Šï¼å¯‡ä¸–å‹³é“æ­‰ï¼ã€€é‡ç£…å–Šè©±ã€Šä¸–ç´€è¡€æ¡ˆã€‹åŠ‡çµ„ï¼šåœæ­¢å¾ŒçºŒè£½ä½œ",
         "å¯‡ä¸–å‹³é“æ­‰äº† è‡ªè²¬å°æ—ç¾©é›„å®¶å±¬äºŒæ¬¡å‚·å®³"),

        ("å¯‡ä¸–å‹³é¦–åº¦ç™¼è²äº† å…¬é–‹é“æ­‰æ—ç¾©é›„å®¶å±¬",
         "å¿«è¨Šï¼å¯‡ä¸–å‹³é“æ­‰ï¼ã€€é‡ç£…å–Šè©±ã€Šä¸–ç´€è¡€æ¡ˆã€‹åŠ‡çµ„ï¼šåœæ­¢å¾ŒçºŒè£½ä½œ"),

        ("å°ç©é›»è‚¡åƒ¹å‰µæ–°é«˜ å¤–è³‡ç‹‚è²·",
         "è­·åœ‹ç¥å±±å†æ”»é ‚ TSMC è‚¡åƒ¹é£†å‡"),
    ]

    for t1, t2 in test_pairs:
        # å…ˆé¡¯ç¤ºæ¼”ç®—æ³•ç›¸ä¼¼åº¦
        algo_sim = title_similarity(t1, t2)
        result = checker.is_same_news(t1, t2)
        print(f"  æ¨™é¡Œ 1: {t1[:40]}...")
        print(f"  æ¨™é¡Œ 2: {t2[:40]}...")
        print(f"  æ¼”ç®—æ³•ç›¸ä¼¼åº¦: {algo_sim:.3f}")
        print(f"  æœ€çµ‚åˆ¤æ–·: {result}")
        print()

    # æ¸¬è©¦æ¡ˆä¾‹ 3: å®Œå…¨ä¸åŒçš„æ–°è
    print("\næ¸¬è©¦ 3: å®Œå…¨ä¸åŒçš„æ–°è")
    different_pairs = [
        ("å°ç©é›»è‚¡åƒ¹å‰µæ–°é«˜",
         "NONOæ²æ€§ä¾µæ¡ˆ2å¹´å¤±æ¥­ï¼æ„›å¦»æœ±æµ·å›è¿‘æ³æ›"),

        ("é»ƒåœ‹æ˜Œæ”¿è¦‹é­æ‰“è‡‰",
         "å›å®¿èˆè¦‹ã€Œ6å¼µæ¯›è‡‰è²¼çª—å‡è¦–ã€å¥³å¤§ç”Ÿåš‡å‘†"),
    ]

    for t1, t2 in different_pairs:
        algo_sim = title_similarity(t1, t2)
        result = checker.is_same_news(t1, t2)
        print(f"  æ¨™é¡Œ 1: {t1[:40]}...")
        print(f"  æ¨™é¡Œ 2: {t2[:40]}...")
        print(f"  æ¼”ç®—æ³•ç›¸ä¼¼åº¦: {algo_sim:.3f}")
        print(f"  æœ€çµ‚åˆ¤æ–·: {result} (é æœŸ: False)")
        print()

    # é¡¯ç¤ºçµ±è¨ˆ
    stats = checker.get_statistics()
    print("=" * 60)
    print("ğŸ“Š çµ±è¨ˆè³‡è¨Š:")
    print(f"  LLM å·²å•Ÿç”¨: {stats['llm_enabled']}")
    print(f"  LLM èª¿ç”¨æ¬¡æ•¸: {stats['llm_call_count']}")
    print("=" * 60)


if __name__ == "__main__":
    test_hybrid_checker()
