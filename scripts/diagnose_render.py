#!/usr/bin/env python3
"""
è¨ºæ–· Render ç’°å¢ƒå•é¡Œ
æ¨¡æ“¬ä½è¨˜æ†¶é«”å’Œç¶²è·¯å»¶é²ç’°å¢ƒ
"""

import os
import psutil
import time
import traceback
from news_dashboard import NewsDashboard

def get_memory_usage():
    """å–å¾—ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
    process = psutil.Process()
    mem_info = process.memory_info()
    return mem_info.rss / 1024 / 1024  # è½‰æ›ç‚º MB

def diagnose():
    print("=" * 60)
    print("ğŸ” Render ç’°å¢ƒè¨ºæ–·å·¥å…·")
    print("=" * 60)

    # 1. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    print("\n1ï¸âƒ£  æª¢æŸ¥ç’°å¢ƒè®Šæ•¸...")
    required_vars = ["OPENAI_API_KEY", "OPENAI_MODEL"]
    for var in required_vars:
        value = os.getenv(var)
        if value:
            # éš±è— API Key çš„å¤§éƒ¨åˆ†å…§å®¹
            if "KEY" in var:
                display_value = f"{value[:10]}...{value[-4:]}"
            else:
                display_value = value
            print(f"   âœ… {var} = {display_value}")
        else:
            print(f"   âŒ {var} = æœªè¨­å®š")

    # 2. æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
    print("\n2ï¸âƒ£  è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§...")
    print(f"   åˆå§‹è¨˜æ†¶é«”: {get_memory_usage():.2f} MB")

    # 3. æ¸¬è©¦å®Œæ•´æµç¨‹
    print("\n3ï¸âƒ£  æ¸¬è©¦å®Œæ•´çˆ¬å–æµç¨‹...")

    try:
        dashboard = NewsDashboard()
        print(f"   Dashboard åˆå§‹åŒ–å¾Œ: {get_memory_usage():.2f} MB")

        # æ¸¬è©¦çˆ¬å–
        print("\n   é–‹å§‹çˆ¬å–æ–°èä¾†æº...")
        start_time = time.time()

        all_source_items = {}
        sources_to_crawl = ["UDN", "TVBS", "ä¸­æ™‚æ–°èç¶²", "ä¸‰ç«‹æ–°èç¶²"]

        for source_name in sources_to_crawl:
            print(f"\n   ğŸ“° çˆ¬å– {source_name}...")
            items = dashboard.crawl_source(source_name)
            all_source_items[source_name] = items

            mem_usage = get_memory_usage()
            print(f"      â†’ æŠ“å– {len(items)} å‰‡æ–°è")
            print(f"      â†’ è¨˜æ†¶é«”: {mem_usage:.2f} MB")

            # è­¦å‘Šï¼šæ¥è¿‘ 512MB ä¸Šé™
            if mem_usage > 400:
                print(f"      âš ï¸  è­¦å‘Šï¼šè¨˜æ†¶é«”ä½¿ç”¨æ¥è¿‘ 512MB ä¸Šé™ï¼")

        # æ¸¬è©¦ ETtoday çˆ¬å–ï¼ˆå¸¶å¿«å–ï¼‰
        print(f"\n   ğŸ“° çˆ¬å– ETtodayï¼ˆå¸¶å¿«å–ï¼‰...")
        ettoday_items = dashboard.crawl_ettoday()
        print(f"      â†’ æŠ“å– {len(ettoday_items)} å‰‡æ–°è")
        print(f"      â†’ è¨˜æ†¶é«”: {get_memory_usage():.2f} MB")

        # æ¸¬è©¦ç›¸ä¼¼åº¦æ¯”å°
        print(f"\n   ğŸ” æ¸¬è©¦ç›¸ä¼¼åº¦æ¯”å°...")
        missing_news = dashboard.find_missing_news(all_source_items, ettoday_items)

        elapsed = time.time() - start_time
        mem_final = get_memory_usage()

        print(f"\n   âœ… å®Œæ•´æµç¨‹æ¸¬è©¦æˆåŠŸï¼")
        print(f"      â†’ è€—æ™‚: {elapsed:.2f} ç§’")
        print(f"      â†’ æœ€çµ‚è¨˜æ†¶é«”: {mem_final:.2f} MB")
        print(f"      â†’ æ‰¾åˆ°ç¼ºå°‘æ–°è: {len(missing_news)} å‰‡")

        # é¡¯ç¤º LLM çµ±è¨ˆ
        stats = dashboard.similarity_checker.get_statistics()
        print(f"      â†’ LLM èª¿ç”¨æ¬¡æ•¸: {stats['llm_call_count']}")

        # æª¢æŸ¥æ˜¯å¦è¶…é 512MB
        if mem_final > 512:
            print(f"\n   âŒ éŒ¯èª¤ï¼šè¨˜æ†¶é«”ä½¿ç”¨è¶…é 512MB ä¸Šé™ï¼")
            print(f"      é€™å¯èƒ½æ˜¯ Render å…è²»æ–¹æ¡ˆå¤±æ•—çš„åŸå› ã€‚")
            return False

        # æª¢æŸ¥æ˜¯å¦è¶…é 300 ç§’
        if elapsed > 300:
            print(f"\n   âŒ éŒ¯èª¤ï¼šåŸ·è¡Œæ™‚é–“è¶…é 300 ç§’ worker timeoutï¼")
            return False

        return True

    except Exception as e:
        print(f"\n   âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{type(e).__name__}: {e}")
        print(f"\n   å®Œæ•´éŒ¯èª¤å †ç–Šï¼š")
        traceback.print_exc()
        print(f"\n   æœ€çµ‚è¨˜æ†¶é«”: {get_memory_usage():.2f} MB")
        return False

def suggest_fixes():
    """æä¾›ä¿®å¾©å»ºè­°"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ ä¿®å¾©å»ºè­°")
    print("=" * 60)

    mem_usage = get_memory_usage()

    if mem_usage > 400:
        print("\nğŸ”´ è¨˜æ†¶é«”å•é¡Œï¼š")
        print("   1. å‡ç´š Render æ–¹æ¡ˆï¼ˆä»˜è²»æ–¹æ¡ˆæœ‰æ›´å¤šè¨˜æ†¶é«”ï¼‰")
        print("   2. æ¸›å°‘ max_itemsï¼ˆ25 â†’ 15ï¼‰é™ä½è³‡æ–™é‡")
        print("   3. ä½¿ç”¨ä¸²æµè™•ç†ï¼ˆä¸è¦ä¸€æ¬¡è¼‰å…¥æ‰€æœ‰æ–°èï¼‰")
        print("   4. å®šæœŸæ¸…ç†è¨˜æ†¶é«”ï¼ˆdel ä¸éœ€è¦çš„è®Šæ•¸ï¼‰")

    print("\nğŸŸ¡ Timeout å•é¡Œï¼š")
    print("   1. å·²è¨­å®š API timeout (10ç§’) âœ…")
    print("   2. å·²è¨­å®š worker timeout (300ç§’) âœ…")
    print("   3. è€ƒæ…®ä½¿ç”¨ async å¹³è¡Œè™•ç†ï¼ˆåŠ é€Ÿ LLM èª¿ç”¨ï¼‰")

    print("\nğŸŸ¢ ç’°å¢ƒè®Šæ•¸ï¼š")
    print("   ç¢ºèª Render ç’°å¢ƒè®Šæ•¸è¨­å®šï¼š")
    print("   - OPENAI_API_KEY")
    print("   - OPENAI_MODEL=gpt-4.1-nano-2025-04-14")
    print("   - ANTHROPIC_API_KEY")

if __name__ == "__main__":
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤è…³æœ¬æœƒåŸ·è¡Œå¯¦éš›çš„ API èª¿ç”¨å’Œçˆ¬å–")
    print("   è«‹ç¢ºèªå·²è¨­å®šç’°å¢ƒè®Šæ•¸ï¼šOPENAI_API_KEY, OPENAI_MODEL\n")

    input("æŒ‰ Enter é–‹å§‹è¨ºæ–·...")

    success = diagnose()

    if not success:
        suggest_fixes()
    else:
        print("\nâœ… è¨ºæ–·å®Œæˆï¼Œæ‰€æœ‰æª¢æŸ¥é€šéï¼")
        print("   å¦‚æœ Render ä»ç„¶å¤±æ•—ï¼Œè«‹æä¾›å®Œæ•´çš„ Render æ—¥èªŒã€‚")
