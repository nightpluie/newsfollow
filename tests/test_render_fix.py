#!/usr/bin/env python3
"""
æ¸¬è©¦è…³æœ¬ï¼šæ¨¡æ“¬å¤§é‡æ–°èæ¨™é¡Œæ¯”å°ï¼Œé©—è­‰ç·©å­˜åˆ†è©çš„æ•ˆèƒ½èˆ‡è¨˜æ†¶é«”å›æ”¶
"""
import time
import random
import jieba
import gc
import sys
import os

# ç¢ºä¿èƒ½å°å…¥ main.py
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from main import title_similarity, get_jieba_tokens

def generate_fake_titles(count=100):
    """ç”Ÿæˆå‡æ–°èæ¨™é¡Œ"""
    subjects = ["å°ç©é›»", "è¼é”", "è˜‹æœ", "ç‰¹æ–¯æ‹‰", "é¦¬æ–¯å…‹", "é»ƒä»å‹³", "åº«å…‹", "æ‹œç™»", "å·æ™®"]
    actions = ["å®£å¸ƒ", "æ¨å‡º", "è£å“¡", "å¤§æ¼²", "æš´è·Œ", "æ”¶è³¼", "æŠ•è³‡", "è¨ªå°", "æ¼”è¬›"]
    objects = ["æ–°æ™¶ç‰‡", "é›»å‹•è»Š", "AIæ¨¡å‹", "è‚¡åƒ¹", "è²¡å ±", "iPhone 16", "è¶…ç´šé›»è…¦"]
    suffixes = ["éœ‡æ’¼æ¥­ç•Œ", "åˆ†æå¸«çœ‹å¥½", "è‚¡æ°‘å—¨ç¿»", "å¼•ç™¼é—œæ³¨", "å¸‚å ´è§£è®€", "æ‡¶äººåŒ…", "æœ€æ–°æ¶ˆæ¯"]
    
    titles = []
    for _ in range(count):
        t = f"{random.choice(subjects)}{random.choice(actions)}{random.choice(objects)} {random.choice(suffixes)}"
        titles.append(t)
    return titles

def test_performance():
    print("="*60)
    print("ğŸš€ é–‹å§‹æ•ˆèƒ½æ¸¬è©¦ (æ¨¡æ“¬ Render ç’°å¢ƒ)")
    print("="*60)
    
    # é ç†± jieba
    start = time.time()
    jieba.cut("é ç†±")
    print(f"ğŸ“¦ Jieba åˆå§‹åŒ–è€—æ™‚: {time.time() - start:.4f}s")
    
    # ç”¢ç”Ÿæ¸¬è©¦è³‡æ–™
    N = 100  # æ¨¡æ“¬ 5 å€‹ä¾†æº x 20 ç¯‡ = 100 ç¯‡
    M = 100  # æ¨¡æ“¬ ETtoday 100 ç¯‡
    
    print(f"ğŸ“Š ç”¢ç”Ÿæ¸¬è©¦è³‡æ–™: ä¾†æºæ–°è {N} ç¯‡ vs ETtoday {M} ç¯‡")
    source_titles = generate_fake_titles(N)
    ettoday_titles = generate_fake_titles(M)
    
    # ç¬¬ä¸€æ¬¡åŸ·è¡Œ (å»ºç«‹ç·©å­˜)
    print("\nğŸ”„ ç¬¬ 1 æ¬¡æ¯”å° (å»ºç«‹ç·©å­˜)...")
    start_time = time.time()
    comparisons = 0
    
    for t1 in source_titles:
        for t2 in ettoday_titles:
            sim = title_similarity(t1, t2)
            comparisons += 1
            
    duration1 = time.time() - start_time
    print(f"âœ… å®Œæˆ {comparisons} æ¬¡æ¯”å°ï¼Œè€—æ™‚: {duration1:.4f}s")
    print(f"   å¹³å‡æ¯å°è€—æ™‚: {duration1/comparisons*1000:.4f}ms")
    
    # é©—è­‰ç·©å­˜è³‡è¨Š
    info = get_jieba_tokens.cache_info()
    print(f"ğŸ’¾ ç·©å­˜ç‹€æ…‹: {info}")
    
    # ç¬¬äºŒæ¬¡åŸ·è¡Œ (ä½¿ç”¨ç·©å­˜) - æ¨¡æ“¬ä¸‹ä¸€è¼ªåˆ†ææˆ–é‡è¤‡æ¨™é¡Œ
    print("\nğŸ”„ ç¬¬ 2 æ¬¡æ¯”å° (æ¨¡æ“¬é‡è¤‡æ¨™é¡Œ/ä¸‹ä¸€è¼ª)...")
    start_time = time.time()
    comparisons = 0
    
    # æ•…æ„é‡è¤‡ä½¿ç”¨ç›¸åŒçš„æ¨™é¡Œåˆ—è¡¨
    for t1 in source_titles:
        for t2 in ettoday_titles:
            sim = title_similarity(t1, t2)
            comparisons += 1
            
    duration2 = time.time() - start_time
    print(f"âœ… å®Œæˆ {comparisons} æ¬¡æ¯”å°ï¼Œè€—æ™‚: {duration2:.4f}s")
    print(f"ğŸš€ æ•ˆèƒ½æå‡: {(duration1 / duration2):.2f}x")
    
    print("\nğŸ§¹ æ¸¬è©¦ gc.collect()...")
    start_gc = time.time()
    gc.collect()
    print(f"âœ… GC è€—æ™‚: {time.time() - start_gc:.4f}s")

if __name__ == "__main__":
    test_performance()
